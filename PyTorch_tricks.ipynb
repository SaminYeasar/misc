{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([1, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samin/environments/py36_baseline/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# use of \"tensor.view()\"\"\n",
    "import torch\n",
    "a = torch.range(1, 16)\n",
    "print( a.view(4,4).shape )\n",
    "print( a.view(1,4,4).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = 1; number of columns = 16\n"
     ]
    }
   ],
   "source": [
    "a = a.view(1,16)\n",
    "print('number of rows = {}; number of columns = {}'.format( a.size(0),a.size(1) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
       "         15., 16.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(a.size(0),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output configuration of conv layer 1 is = [25. 19.]\n",
      "output configuration of conv layer 2 is = [11.  8.]\n",
      "output configuration of conv layer 3 is = [9. 6.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9., 6.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "# compute configuration of Conv layers\n",
    "######################################\n",
    "import numpy as np\n",
    "\n",
    "layer = 3\n",
    "n_w = 105\n",
    "n_h = 80\n",
    "padding = np.array([0,0,0])\n",
    "filter_ = np.array([8,4,3])\n",
    "stride = np.array([4,2,1])\n",
    "\n",
    "import numpy as np\n",
    "def cal_(n,p,f,s):\n",
    "    return np.floor((n+(2*p)-f)/s+1)\n",
    "\n",
    "\n",
    "for itr in range(layer):\n",
    "    cov_out = np.array([cal_(n_w,padding[itr],filter_[itr],stride[itr]),cal_(n_h,padding[itr],filter_[itr],stride[itr])])\n",
    "    n_w = cov_out[0]\n",
    "    n_h = cov_out[1]\n",
    "    print('output configuration of conv layer {} is = {}'.format(itr+1,cov_out) )\n",
    "cov_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  7]\n"
     ]
    }
   ],
   "source": [
    "n_w = 105\n",
    "n_h = 80\n",
    "def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "    return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(n_w)))\n",
    "convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(n_h)))\n",
    "print(np.array([convw,convh]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output configuration of conv layer 1 is = [51. 38.]\n",
      "output configuration of conv layer 2 is = [24. 17.]\n",
      "output configuration of conv layer 3 is = [10.  7.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([10.,  7.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 3\n",
    "n_w = 105\n",
    "n_h = 80\n",
    "padding = np.array([0,0,0])\n",
    "filter_ = np.array([5,5,5])\n",
    "stride = np.array([2,2,2])\n",
    "\n",
    "import numpy as np\n",
    "def cal_(n,p,f,s):\n",
    "    return np.floor((n+(2*p)-f)/s+1)\n",
    "\n",
    "\n",
    "for itr in range(layer):\n",
    "    cov_out = np.array([cal_(n_w,padding[itr],filter_[itr],stride[itr]),cal_(n_h,padding[itr],filter_[itr],stride[itr])])\n",
    "    n_w = cov_out[0]\n",
    "    n_h = cov_out[1]\n",
    "    print('output configuration of conv layer {} is = {}'.format(itr+1,cov_out) )\n",
    "cov_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samin/environments/py36_baseline/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x = torch.range(1, 10*15*64)\n",
    "x = x.view(10,15,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 960])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(x.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samin/environments/py36_baseline/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x = torch.range(1, 32*6)\n",
    "x = x.view(32,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   2.,   3.,   4.,   5.,   6.],\n",
       "        [  7.,   8.,   9.,  10.,  11.,  12.],\n",
       "        [ 13.,  14.,  15.,  16.,  17.,  18.],\n",
       "        [ 19.,  20.,  21.,  22.,  23.,  24.],\n",
       "        [ 25.,  26.,  27.,  28.,  29.,  30.],\n",
       "        [ 31.,  32.,  33.,  34.,  35.,  36.],\n",
       "        [ 37.,  38.,  39.,  40.,  41.,  42.],\n",
       "        [ 43.,  44.,  45.,  46.,  47.,  48.],\n",
       "        [ 49.,  50.,  51.,  52.,  53.,  54.],\n",
       "        [ 55.,  56.,  57.,  58.,  59.,  60.],\n",
       "        [ 61.,  62.,  63.,  64.,  65.,  66.],\n",
       "        [ 67.,  68.,  69.,  70.,  71.,  72.],\n",
       "        [ 73.,  74.,  75.,  76.,  77.,  78.],\n",
       "        [ 79.,  80.,  81.,  82.,  83.,  84.],\n",
       "        [ 85.,  86.,  87.,  88.,  89.,  90.],\n",
       "        [ 91.,  92.,  93.,  94.,  95.,  96.],\n",
       "        [ 97.,  98.,  99., 100., 101., 102.],\n",
       "        [103., 104., 105., 106., 107., 108.],\n",
       "        [109., 110., 111., 112., 113., 114.],\n",
       "        [115., 116., 117., 118., 119., 120.],\n",
       "        [121., 122., 123., 124., 125., 126.],\n",
       "        [127., 128., 129., 130., 131., 132.],\n",
       "        [133., 134., 135., 136., 137., 138.],\n",
       "        [139., 140., 141., 142., 143., 144.],\n",
       "        [145., 146., 147., 148., 149., 150.],\n",
       "        [151., 152., 153., 154., 155., 156.],\n",
       "        [157., 158., 159., 160., 161., 162.],\n",
       "        [163., 164., 165., 166., 167., 168.],\n",
       "        [169., 170., 171., 172., 173., 174.],\n",
       "        [175., 176., 177., 178., 179., 180.],\n",
       "        [181., 182., 183., 184., 185., 186.],\n",
       "        [187., 188., 189., 190., 191., 192.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x.max(1)) # is a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.max(1)) # tuple of two elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  6.,  12.,  18.,  24.,  30.,  36.,  42.,  48.,  54.,  60.,  66.,  72.,\n",
       "          78.,  84.,  90.,  96., 102., 108., 114., 120., 126., 132., 138., 144.,\n",
       "         150., 156., 162., 168., 174., 180., 186., 192.]),\n",
       " tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for .max (1) ([maximum along column][maximum value position along the column])\n",
    "# for .max (0) ([maximum along row][maximum value position along the row])\n",
    "x.max(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  6.,  12.,  18.,  24.,  30.,  36.,  42.,  48.,  54.,  60.,  66.,  72.,\n",
       "         78.,  84.,  90.,  96., 102., 108., 114., 120., 126., 132., 138., 144.,\n",
       "        150., 156., 162., 168., 174., 180., 186., 192.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.max(1)[0] # chooses to give up only max values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .detach() detaches the output from the computationnal graph. So no gradient will be backproped along this variable \\\\\n",
    "\n",
    "* link: https://discuss.pytorch.org/t/detach-no-grad-and-requires-grad/16915/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.unsqueeze(obj,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samin/environments/py36_baseline/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x = torch.range(1, 32*6)\n",
    "x = x.view(32,6)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6])\n"
     ]
    }
   ],
   "source": [
    "print( x.squeeze().size() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 6])\n"
     ]
    }
   ],
   "source": [
    "print(x.squeeze().unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "print(x.squeeze().unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x.squeeze().unsqueeze(2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 1],\n",
      "        [4, 3]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "print( t.gather( 1, torch.tensor([[0,0],[1,0]])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[2],\n",
      "        [1],\n",
      "        [5],\n",
      "        [2],\n",
      "        [4],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "action = list( np.random.randint(0,6,10) )\n",
    "action = torch.LongTensor(action)  # ** must be a LongTensor to be used as Mask **\n",
    "action = action.view(-1,1)\n",
    "print(action.size())\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n",
      "tensor([[160., 168., 185., 156., 117., 127.],\n",
      "        [193., 144., 102., 197., 130., 132.],\n",
      "        [141., 153., 185., 119., 116., 132.],\n",
      "        [114., 114., 101., 139., 185., 141.],\n",
      "        [140., 155., 109., 172., 160., 124.],\n",
      "        [133., 157., 138., 100., 180., 152.],\n",
      "        [108., 108., 185., 127., 196., 103.],\n",
      "        [179., 127., 121., 142., 172., 173.],\n",
      "        [162., 158., 122., 181., 174., 199.],\n",
      "        [183., 117., 128., 148., 168., 172.]])\n"
     ]
    }
   ],
   "source": [
    "Q = list( np.random.randint(100,200,10*6) )\n",
    "Q = torch.Tensor(Q).view(10,6)  # shape = ( batch_size 32 , no of actions 6 )\n",
    "print(Q.size())\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[185.],\n",
       "        [144.],\n",
       "        [132.],\n",
       "        [101.],\n",
       "        [160.],\n",
       "        [138.],\n",
       "        [185.],\n",
       "        [142.],\n",
       "        [174.],\n",
       "        [168.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the actions at each state that gives maximum Q and return those Q values\n",
    "Q.gather(1,action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find done==True is list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* link: https://stackoverflow.com/questions/21448225/getting-indices-of-true-values-in-a-boolean-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 7]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [False, False, False, False, True, True, False, True, False, False, False, False, False, False, False, False]\n",
    "mask = [i for i, x in enumerate(t) if x]\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
